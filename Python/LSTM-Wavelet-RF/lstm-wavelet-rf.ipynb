{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/no_exogenous/data.csv'\n",
    "FREQ = 'h'\n",
    "YEAR = 2021\n",
    "LOOK_BACK = 36\n",
    "WAVELET = 'db4'\n",
    "LEVELS = 3\n",
    "LSTM_EPOCHS = 200\n",
    "LSTM_BATCH_SIZE = 128\n",
    "RF_MAX_DEPTH = 10\n",
    "RF_N_ESTIMATORS = 100\n",
    "OUTPUT_PATH = f'data/predictions_lstm_wavelet_rf_{YEAR}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = pd.read_csv(DATA_PATH, parse_dates=['timestamp'])\n",
    "    data = data.set_index('timestamp').asfreq(FREQ).dropna()\n",
    "    data['hour'] = data.index.hour\n",
    "    data['day_of_week'] = data.index.dayofweek\n",
    "    data['month'] = data.index.month\n",
    "    data['year'] = data.index.year\n",
    "    data['is_weekend'] = (data.index.dayofweek >= 5).astype(int)\n",
    "    data['quarter'] = data.index.quarter\n",
    "    data['day_of_year'] = data.index.dayofyear\n",
    "    return data\n",
    "\n",
    "def decompose_signal(series):\n",
    "    coeffs = pywt.wavedec(series, WAVELET, level=LEVELS)\n",
    "    names = ['cA'] + [f'cD{i}' for i in range(LEVELS, 0, -1)]\n",
    "    comps = {}\n",
    "    for i, name in enumerate(names):\n",
    "        temp = [np.zeros_like(c) for c in coeffs]\n",
    "        temp[i] = coeffs[i]\n",
    "        rec = pywt.waverec(temp, WAVELET)\n",
    "        comps[name] = rec[:len(series)]\n",
    "    return comps\n",
    "\n",
    "def create_seq(X, y):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(LOOK_BACK, len(X)):\n",
    "        Xs.append(X[i-LOOK_BACK:i])\n",
    "        ys.append(y[i])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "train = data[(data['year'] < YEAR) & (data['year'] > YEAR - 5)]\n",
    "test  = data[data['year'] == YEAR]\n",
    "calendar_cols = ['hour','day_of_week','month','is_weekend','quarter','day_of_year']\n",
    "scaler_feat = StandardScaler().fit(train[calendar_cols])\n",
    "scaler_tgt  = StandardScaler().fit(train[['value']])\n",
    "train_feat  = scaler_feat.transform(train[calendar_cols])\n",
    "test_feat   = scaler_feat.transform(test[calendar_cols])\n",
    "train_tgt   = scaler_tgt.transform(train[['value']]).flatten()\n",
    "components  = decompose_signal(train_tgt)\n",
    "datasets    = {name: create_seq(np.hstack([train_feat, train_tgt.reshape(-1,1)]), comp)\n",
    "               for name, comp in components.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708084c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for name, (Xs, ys) in datasets.items():\n",
    "    m = Sequential([\n",
    "        LSTM(128, return_sequences=True, input_shape=(LOOK_BACK, Xs.shape[2])),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        LSTM(36),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    m.compile('adam', 'mse')\n",
    "    m.fit(Xs, ys, epochs=LSTM_EPOCHS, batch_size=LSTM_BATCH_SIZE, verbose=1)\n",
    "    models[name] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = np.hstack([train_feat] + [components[name].reshape(-1,1) for name in sorted(components.keys())])\n",
    "y_rf = train_tgt\n",
    "rf = RandomForestRegressor(max_depth=RF_MAX_DEPTH, n_estimators=RF_N_ESTIMATORS, random_state=42)\n",
    "rf.fit(X_rf, y_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = np.hstack([train_feat, train_tgt.reshape(-1,1)])[-LOOK_BACK:]\n",
    "preds = []\n",
    "for i in range(len(test_feat)):\n",
    "    inp = buf.reshape(1, LOOK_BACK, buf.shape[1])\n",
    "    comp_pred = [models[name].predict(inp)[0,0] for name in sorted(models.keys())]\n",
    "    rf_in = np.hstack([test_feat[i], comp_pred]).reshape(1, -1)\n",
    "    p = rf.predict(rf_in)[0]\n",
    "    preds.append(p)\n",
    "    buf = np.vstack([buf[1:], np.hstack([test_feat[i], p])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebce80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = scaler_tgt.inverse_transform(np.array(preds).reshape(-1,1)).flatten()\n",
    "out = test.copy()\n",
    "out['value'] = preds\n",
    "out.to_csv(OUTPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
